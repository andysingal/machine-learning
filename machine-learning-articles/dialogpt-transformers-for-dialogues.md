---
title: "DialoGPT: Transformers for Dialogues"
date: "2021-03-16"
categories:
  - "buffer"
  - "deep-learning"
tags:
  - "dialogpt"
  - "dialogue"
  - "machine-learning"
  - "text"
  - "transformer"
---

DialoGPT is “a tunable gigaword-scale neural network model for generation of conversational responses, trained on Reddit data”. It uses a Transformer based architecture for doing so, because of their great empirical success. Doing so, the creators have attempted to resolve challenges present with neural response generation – i.e. generating texts relevant to the prompt. These are related to the fact that conversations are informal, noisy, and contain abbreviations or errors.
